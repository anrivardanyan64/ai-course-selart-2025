{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f42de511",
   "metadata": {},
   "source": [
    "Module 3, Session 1- Practical Exercises\n",
    "Objective- Gain hands-on experience collecting data from the web using APIs and web scraping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7833f3",
   "metadata": {},
   "source": [
    "Exercise 1:\n",
    "The API Request\n",
    "\n",
    "Fetch user data from https://jsonplaceholder.typicode.com/users using requests and pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f66bebcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leanne Graham - Sincere@april.biz\n",
      "Ervin Howell - Shanna@melissa.tv\n",
      "Clementine Bauch - Nathan@yesenia.net\n",
      "Patricia Lebsack - Julianne.OConner@kory.org\n",
      "Chelsey Dietrich - Lucio_Hettinger@annie.ca\n",
      "Mrs. Dennis Schulist - Karley_Dach@jasper.info\n",
      "Kurtis Weissnat - Telly.Hoeger@billy.biz\n",
      "Nicholas Runolfsdottir V - Sherwood@rosamond.me\n",
      "Glenna Reichert - Chaim_McDermott@dana.io\n",
      "Clementina DuBuque - Rey.Padberg@karina.biz\n",
      "               name                      email\n",
      "0     Leanne Graham          Sincere@april.biz\n",
      "1      Ervin Howell          Shanna@melissa.tv\n",
      "2  Clementine Bauch         Nathan@yesenia.net\n",
      "3  Patricia Lebsack  Julianne.OConner@kory.org\n",
      "4  Chelsey Dietrich   Lucio_Hettinger@annie.ca\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://jsonplaceholder.typicode.com/users\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    users = response.json()\n",
    "    for user in users:\n",
    "        print(user['name'], \"-\", user['email'])\n",
    "    \n",
    "    df_users = pd.DataFrame(users)\n",
    "    print(df_users[['name', 'email']].head())\n",
    "else:\n",
    "    print(\"Request error:\", response.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e84d611",
   "metadata": {},
   "source": [
    "Exercise 2:\n",
    "The Web Scraper\n",
    "\n",
    "Scrape the main table of largest companies by revenue from Wikipedia into a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "324902da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 tables on the page.\n",
      "  Ranks                             Name                        Industry  \\\n",
      "  Ranks                             Name                        Industry   \n",
      "0     1                          Walmart                          Retail   \n",
      "1     2                           Amazon  Retail  information technology   \n",
      "2     3  State Grid Corporation of China                     Electricity   \n",
      "3     4                     Saudi Aramco                     Oil and gas   \n",
      "4     5  China Petrochemical Corporation                     Oil and gas   \n",
      "\n",
      "            Revenue            Profit Employees Headquarters[note 1]  \\\n",
      "  USD (in millions) USD (in millions) Employees Headquarters[note 1]   \n",
      "0          $680,985           $19,436   2100000        United States   \n",
      "1          $637,959           $59,248   1556000        United States   \n",
      "2          $545,948            $9,204   1361423                China   \n",
      "3          $480,446          $106,246     73311         Saudi Arabia   \n",
      "4          $429,700            $9,393    513434                China   \n",
      "\n",
      "  State-owned Ref.  \n",
      "  State-owned Ref.  \n",
      "0         NaN  [1]  \n",
      "1         NaN  [4]  \n",
      "2         NaN  [5]  \n",
      "3         NaN  [6]  \n",
      "4         NaN  [7]  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_2980\\800456091.py:14: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tables = pd.read_html(response.text)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_largest_companies_by_revenue\"\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 \"\n",
    "                  \"(KHTML, like Gecko) Chrome/142.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    tables = pd.read_html(response.text)\n",
    "    print(f\"Found {len(tables)} tables on the page.\")\n",
    "    df_companies = tables[0]\n",
    "    print(df_companies.head())\n",
    "else:\n",
    "    print(\"Request error:\", response.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b058a406",
   "metadata": {},
   "source": [
    "Exercise 3:\n",
    "The Strategist\n",
    "\n",
    "1.API vs Web Scraping: My first approach would be to look for an official weather API, because it is more reliable, the data is structured, and updates automatically.  \n",
    "\n",
    "2.Potential problems with API: Some APIs may be paid or limit the number of requests.  \n",
    "Sometimes the data is not provided in the required format or there may be delays.  \n",
    "\n",
    "3.Potential problems with Web Scraping: The website structure can change, which may break the script.  \n",
    "Some websites have protections against automated data collection (e.g., Captcha or IP blocking).  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
